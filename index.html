<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Ground Texture Sim: Ground Texture Simulation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Ground Texture Sim<span id="projectnumber">&#160;4.0.0</span>
   </div>
   <div id="projectbrief">A realistic ground texture data generator for monocular SLAM</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Ground Texture Simulation </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p ><a class="anchor" id="md_README"></a> <img src="https://github.com/kylerobots/ground-texture-sim/actions/workflows/tests.yml/badge.svg?branch=main" alt="Run Tests" style="pointer-events: none;" class="inline"/> <img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/wiki/kylerobots/ground-texture-sim/python-coverage-comment-action-badge.json" alt="Coverage badge" class="inline"/> <img src="https://github.com/kylerobots/ground-texture-sim/actions/workflows/deploy_pages.yml/badge.svg?branch=main" alt="Deploy Documentation" style="pointer-events: none;" class="inline"/> <a href="https://open.vscode.dev/kylerobots/ground-texture-sim" target="_blank"><img src="https://open.vscode.dev/badges/open-in-vscode.svg" alt="Open in Visual Studio Code" style="pointer-events: none;" class="inline"/></a></p>
<h1><a class="anchor" id="autotoc_md1"></a>
Table of Contents</h1>
<ol type="1">
<li><a href="#license" target="_blank">License</a></li>
<li><a href="#install" target="_blank">Install</a><ol type="a">
<li><a href="#blender-installed-locally" target="_blank">Local Blender</a></li>
<li><a href="#build-container-locally" target="_blank">Local Container</a></li>
<li><a href="#pull-docker-hub-container" target="_blank">Prebuilt Container</a></li>
</ol>
</li>
<li><a href="#running" target="_blank">Running</a></li>
<li><a href="#customization" target="_blank">Customization</a><ol type="a">
<li><a href="#customizing-the-output" target="_blank">Customizing the Output</a></li>
<li><a href="#customizing-the-environment" target="_blank">Customizing the Environment</a></li>
</ol>
</li>
</ol>
<p >This package helps create realistic ground texture synthetic images for use by a monocular SLAM application. To promote fidelity, it uses physics based rendering (PBR) to accurately simulate the appearance of the ground texture. Additionally, it avoids the repetition of tiles common in most simulated floors.</p>
<p ><a href="https://github.com/kylerobots/ground-texture-sim" target="_blank">Source Code</a></p>
<p ><a href="https://kylerobots.github.io/ground-texture-sim/" target="_blank">Documentation</a></p>
<h1><a class="anchor" id="autotoc_md2"></a>
License</h1>
<p >Copyright 2022 Kyle M. Hart</p>
<p >See <a class="el" href="md_LICENSE.html">LICENSE</a> for more info.</p>
<p >Since v3.0.0 and subsequent versions rely on Blender's API, this project is licensed under GPLv3 and later. There is no code reuse between v3.0.0 and previous versions, so no conflict with previous licenses.</p>
<p >The example texture provided in this repository comes from <a href="https://polyhaven.com/a/t_brick_floor_002" target="_blank">Poly Haven</a> and is licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/" target="_blank">CC0</a></p>
<p >The format for the data comes from this repository: <a href="https://github.com/JanFabianSchmid/HD_Ground">https://github.com/JanFabianSchmid/HD_Ground</a> which is licensed under CC BY-SA: 4.0</p>
<h1><a class="anchor" id="autotoc_md3"></a>
Install</h1>
<p >There are three ways to use this, depending on your preferred setup. Regardless of the setup, make sure you <b>PYTHONPATH</b> environmental variable contains the directory of this code so that Blender can find all of the scripts.</p>
<h2><a class="anchor" id="autotoc_md4"></a>
Blender Installed Locally</h2>
<p >If you already have Blender installed locally, you only need to clone the repository to your computer:</p>
<div class="fragment"><div class="line">git clone --branch VERSION https://github.com/kylerobots/ground-texture-sim.git</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md5"></a>
Build Container Locally</h2>
<p >If you don't have Blender, this code also provides a Dockerfile that will create an image with Blender. Just run the following:</p>
<div class="fragment"><div class="line">git clone --branch VERSION https://github.com/kylerobots/ground-texture-sim.git</div>
<div class="line">cd ground-texture-sim</div>
<div class="line">docker build --target run -t ground-texture-sim:run .</div>
</div><!-- fragment --><p >The resulting image will have Blender, the generation scripts, and the example environment. If you are only interacting with the environment via this code, you don't need to get the GUI working. Any other features, such as editing the lighting, and you do.</p>
<h2><a class="anchor" id="autotoc_md6"></a>
Pull Docker Hub Container</h2>
<p >If you don't want to build anything yourself, you can just pull a prebuilt container from Docker Hub: </p><div class="fragment"><div class="line">docker pull kylerobots/ground-texture-sim:TAG</div>
</div><!-- fragment --><p> Make sure the tag is at least <code>4.0.0</code></p>
<h1><a class="anchor" id="autotoc_md7"></a>
Running</h1>
<p >To run the script, enter the following from the command line in the root directory of the project. This example generates data for the example provided in <em>example_setup</em>. Note that, depending on your settings and computing power, this script may take some time to execute. The script will continually provide progress updates as it goes.</p>
<div class="fragment"><div class="line">blender example_setup/environment.blend -b --python generate_data.py --python-use-system-env -- config.json</div>
</div><!-- fragment --><p >You can substitute <code>example_setup/environment.blend</code> for another Blender environment you may have. Likewise, <code>config.json</code> should be replaced with the name of the configuration JSON file that specifies everything for your project. An example JSON file can be found at the root directory of this project and its content is described below.</p>
<p >The <code>-b</code> flag will run Blender in the background, so you don't need to open it up. However, you may use Blender as usual to adjust lighting, the scene, or anything else not currently supported by this script.</p>
<p >The <code>--python-use-system-env</code> flag allows Blender to search for modules on your PYTHONPATH instead of just within Blender's instance of Python. This is essential for all the necessary code to run, and why PYTHONPATH must point to this code.</p>
<p >The data is output to the location specified by <code>output</code> in the JSON. The general structure is as follows:</p>
<div class="fragment"><div class="line">output/</div>
<div class="line">├─ &lt;sequence/sequence_type&gt;_&lt;date&gt;.test</div>
<div class="line">├─ &lt;sequence/sequence_type&gt;_&lt;date&gt;.txt</div>
<div class="line">├─ &lt;sequence/sequence_type&gt;_&lt;date&gt;_meters.txt</div>
<div class="line">├─ camera_properties/</div>
<div class="line">│  ├─ &lt;camera/name&gt;_intrinsic_matrix.txt</div>
<div class="line">│  ├─ &lt;camera/name&gt;_pose.txt</div>
<div class="line">├─ &lt;sequence/sequence_type&gt;/</div>
<div class="line">│  ├─ &lt;date&gt;/</div>
<div class="line">│  │  ├─ seq&lt;sequence/sequence_number&gt;/</div>
<div class="line">│  │  │  ├─ &lt;image_name&gt;</div>
</div><!-- fragment --><p >Each element in <code>&lt;&gt;</code> is substituted with either a configuration setting or other parameter. The <code>image_name</code> is of the form:</p>
<div class="fragment"><div class="line">HDG2_t&lt;sequence/texture_number&gt;_&lt;sequence_sequence/type&gt;_&lt;date&gt;_s&lt;sequence/sequence_number&gt;_&lt;camera_name&gt;_i&lt;image_number&gt;.png</div>
</div><!-- fragment --><p >The top level files are main lists. The one ending in <code>.test</code> lists a relative path to each image in the sequence. The ones that end in <code>.txt</code> both contain lists alternating between the relative path to each image and a global pose, stored as a 3x3 flattened homogenous matrix. The difference between the two is that the one with a <code>_meters.txt</code> suffix stores the global pose, in meters, of a simulated robot carrying the camera. The one with just <code>.txt</code> notes the pose of the top left pixel of the image, in pixel space. In other words, the origin of this space is the origin of the top left corner of the image taken when the simulated robot is at (0, 0, 0).</p>
<p >Additionally there are two folders. The first, called <code>camera_properties</code>, contains 2 text files. <code>&lt;camera_name&gt;_intrinsic_matrix.txt</code> contains the 3x3 camera matrix. <code>&lt;camera_name&gt;_pose.txt</code> contains the 4x4 homogenous transform representing the pose of the camera with respect to the simulated robot that is following the given trajectory.</p>
<p >The last folder is a series of nested folders containing the images. This comes from the format specified here: <a href="https://github.com/JanFabianSchmid/HD_Ground">https://github.com/JanFabianSchmid/HD_Ground</a></p>
<h1><a class="anchor" id="autotoc_md8"></a>
Customization</h1>
<h2><a class="anchor" id="autotoc_md9"></a>
Customizing the Output</h2>
<p >The below example JSON and table show what values can currently be specified in the configuration JSON. The table also lists if a parameter is required and its default if not required.</p>
<div class="fragment"><div class="line">{</div>
<div class="line">  &quot;trajectory&quot;: &quot;example_setup/trajectories/corners_1x1.txt&quot;,</div>
<div class="line">  &quot;output&quot;: &quot;output&quot;,</div>
<div class="line">  &quot;sequence&quot;: {</div>
<div class="line">    &quot;texture_number&quot;: 1,</div>
<div class="line">    &quot;sequence_type&quot;: &quot;regular&quot;,</div>
<div class="line">    &quot;sequence_number&quot;: 1</div>
<div class="line">  },</div>
<div class="line">  &quot;camera&quot;: {</div>
<div class="line">    &quot;name&quot;: &quot;Camera&quot;,</div>
<div class="line">    &quot;x&quot;: 0.0,</div>
<div class="line">    &quot;y&quot;: 0.0,</div>
<div class="line">    &quot;z&quot;: 0.25,</div>
<div class="line">    &quot;roll&quot;: 0.0,</div>
<div class="line">    &quot;pitch&quot;: 1.5708,</div>
<div class="line">    &quot;yaw&quot;: 0.0</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Parameter Key   </th><th class="markdownTableHeadCenter">Required?   </th><th class="markdownTableHeadCenter">Default Value   </th><th class="markdownTableHeadNone">Description    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">trajectory   </td><td class="markdownTableBodyCenter">Yes   </td><td class="markdownTableBodyCenter"><em>N/A</em>   </td><td class="markdownTableBodyNone">The name of the file to read the list of poses the robot should take. Each line in the file should be of the form <code>x, y, yaw</code> in meters, meters, and radians, respectively    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">output   </td><td class="markdownTableBodyCenter">Yes   </td><td class="markdownTableBodyCenter"><em>N/A</em>   </td><td class="markdownTableBodyNone">The folder the images and calibration file should be written to. Can be absolute or relative    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">sequence/texture_number   </td><td class="markdownTableBodyCenter">Yes   </td><td class="markdownTableBodyCenter"><em>N/A</em>   </td><td class="markdownTableBodyNone">An integer designation of the texture used in this sequence    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">sequence/sequence_type   </td><td class="markdownTableBodyCenter">Yes   </td><td class="markdownTableBodyCenter"><em>N/A</em>   </td><td class="markdownTableBodyNone">A string describing what type of sequence, such as "regular" or "lawnmower"    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">sequence/sequence_number   </td><td class="markdownTableBodyCenter">Yes   </td><td class="markdownTableBodyCenter"><em>N/A</em>   </td><td class="markdownTableBodyNone">A unique integer relative to this particular texture and date of data collection    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">camera/name   </td><td class="markdownTableBodyCenter">Yes   </td><td class="markdownTableBodyCenter"><em>N/A</em>   </td><td class="markdownTableBodyNone">The name in Blender for the camera.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">camera/x   </td><td class="markdownTableBodyCenter">No   </td><td class="markdownTableBodyCenter">0.0   </td><td class="markdownTableBodyNone">The X component of the translation of the camera from the simulated robot's frame.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">camera/y   </td><td class="markdownTableBodyCenter">No   </td><td class="markdownTableBodyCenter">0.0   </td><td class="markdownTableBodyNone">The Y component of the translation of the camera from the simulated robot's frame.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">camera/z   </td><td class="markdownTableBodyCenter">No   </td><td class="markdownTableBodyCenter">0.0   </td><td class="markdownTableBodyNone">The Z component of the translation of the camera from the simulated robot's frame.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">camera/roll   </td><td class="markdownTableBodyCenter">No   </td><td class="markdownTableBodyCenter">0.0   </td><td class="markdownTableBodyNone">The roll of the orientation, in RPY Euler angles and radians, of the camera from the simulated robot's frame    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">camera/pitch   </td><td class="markdownTableBodyCenter">No   </td><td class="markdownTableBodyCenter">1.5708   </td><td class="markdownTableBodyNone">The pitch of the orientation, in RPY Euler angles and radians, of the camera from the simulated robot's frame    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">camera/yaw   </td><td class="markdownTableBodyCenter">No   </td><td class="markdownTableBodyCenter">0.0   </td><td class="markdownTableBodyNone">The yaw of the orientation, in RPY Euler angles and radians, of the camera from the simulated robot's frame   </td></tr>
</table>
<p >Note that while any 6 DOF pose of the camera is technically possible, deviations too far from a downward facing camera may result in undefined behavior. This pose also represents the pose of the camera relative to each trajectory pose. In other words, if the trajectories specified in the trajectory file are a robot's pose on the ground plane, these values are the pose of the camera with respect to the robot's origin. This is provided to allow easy data generation of cases where the camera may be misaligned or off-center. Importantly, the roll, pitch, and yaw are Euler angles applied in that order and are <em>extrinsic</em> rotations. The values are in meters and radians. Additionally, values of zero on all six dimensions will align the camera image with the robot's frame of reference, so it won't be pointed at the ground. You will typically want a pitch of pi / 2.0 or close to that for a downward facing camera. While this is counterintuitive for this application, this adheres to frame conventions in the greater robotics community.</p>
<h2><a class="anchor" id="autotoc_md10"></a>
Customizing the Environment</h2>
<p >For any other setting, such as different textures or image size, you will need to open up Blender and edit the .blend file. This is due to the extremely large number of settings that are possible. Consequently, this guide will not cover them all. However, here are some common items to consider. This assumes basic familiarity with Blender.</p>
<ul>
<li>The device used for rendering can be selected on the <code>render properties</code> pane, under <code>Device</code>. It is encouraged to use the GPU if available.</li>
<li>The quality of the render can be changed by adjusted the <code>Render &gt; Samples</code> setting on the <code>render properties</code> pane. The higher the number, the higher quality the image (and longer render time).</li>
<li>The size of the output image is found in the <code>Output Properties</code> pane, under <code>Format</code>.</li>
<li>To change the ground texture, navigate to the <code>Shading</code> workspace and select the <code>Ground</code> object in the Scene Collection. You will see a bunch of nodes connected together. The four brown ones are the PBR files. Each one is named for the type of file it should hold (e.g. <code>normal</code> for the <code>normal</code> file). Use the file browser on each node to change to a new texture.</li>
<li>The size of the ground can be changed by selecting <code>Ground</code> in the Scene Collection, then navigating to the <code>Object Properties</code> pane. Use the X and Y scale. The example file has a ground that is 2x2 meters. The texture will stretch to fit whatever the ground size is.</li>
<li>The camera parameters are not set as a matrix, but rather as a combination of the image resolution and properties specified in the <code>Object Data Properties</code> pane found when selecting the <code>Camera</code> from the Scene Collection. See <a href="https://visp-doc.inria.fr/doxygen/visp-3.4.0/tutorial-tracking-mb-generic-rgbd-Blender.html">https://visp-doc.inria.fr/doxygen/visp-3.4.0/tutorial-tracking-mb-generic-rgbd-Blender.html</a> for a good overview of how these parameters impact the intrinsic matrix. </li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.2
</small></address>
</body>
</html>
