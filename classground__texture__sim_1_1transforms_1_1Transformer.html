<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Ground Texture Sim: ground_texture_sim.transforms.Transformer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Ground Texture Sim<span id="projectnumber">&#160;4.0.0</span>
   </div>
   <div id="projectbrief">A realistic ground texture data generator for monocular SLAM</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceground__texture__sim.html">ground_texture_sim</a></li><li class="navelem"><a class="el" href="namespaceground__texture__sim_1_1transforms.html">transforms</a></li><li class="navelem"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html">Transformer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="classground__texture__sim_1_1transforms_1_1Transformer-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">ground_texture_sim.transforms.Transformer Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>A class to convert poses and points from one frame to another.  
 <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab2046be7681d2ac072aab5a062ae8c97"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ab2046be7681d2ac072aab5a062ae8c97">__init__</a> (self, numpy.ndarray <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a424e154611f64ac525e608d53232dc83">camera_pose</a>, numpy.ndarray <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6b6145182312e59eed74154c7607dd9a">camera_intrinsic_matrix</a>)</td></tr>
<tr class="memdesc:ab2046be7681d2ac072aab5a062ae8c97"><td class="mdescLeft">&#160;</td><td class="mdescRight">Construct the class with the pose of the camera relative to the robot and camera intrinsic matrix.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#ab2046be7681d2ac072aab5a062ae8c97">More...</a><br /></td></tr>
<tr class="separator:ab2046be7681d2ac072aab5a062ae8c97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6923529981efa026c688314a0895262"><td class="memItemLeft" align="right" valign="top">numpy.ndarray&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad6923529981efa026c688314a0895262">camera_intrinsic_matrix</a> (self)</td></tr>
<tr class="memdesc:ad6923529981efa026c688314a0895262"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the 3x3 camera intrinsic matrix.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad6923529981efa026c688314a0895262">More...</a><br /></td></tr>
<tr class="separator:ad6923529981efa026c688314a0895262"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd817666244a1508a7859f84533c02e4"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#abd817666244a1508a7859f84533c02e4">camera_intrinsic_matrix</a> (self, numpy.ndarray camera_intrinsic_matrix)</td></tr>
<tr class="memdesc:abd817666244a1508a7859f84533c02e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the camera intrinsic matrix.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#abd817666244a1508a7859f84533c02e4">More...</a><br /></td></tr>
<tr class="separator:abd817666244a1508a7859f84533c02e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6fac7a1c805cf77c99e98b38139fdd6d"><td class="memItemLeft" align="right" valign="top">numpy.ndarray&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6fac7a1c805cf77c99e98b38139fdd6d">camera_pose</a> (self)</td></tr>
<tr class="memdesc:a6fac7a1c805cf77c99e98b38139fdd6d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the 4x4 homogenous pose of the camera as measured from the robot.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6fac7a1c805cf77c99e98b38139fdd6d">More...</a><br /></td></tr>
<tr class="separator:a6fac7a1c805cf77c99e98b38139fdd6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac84a739200ea6b87df97d24e661a14e6"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ac84a739200ea6b87df97d24e661a14e6">camera_pose</a> (self, numpy.ndarray camera_pose)</td></tr>
<tr class="memdesc:ac84a739200ea6b87df97d24e661a14e6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the pose of the camera as measured from the robot's frame of reference.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#ac84a739200ea6b87df97d24e661a14e6">More...</a><br /></td></tr>
<tr class="separator:ac84a739200ea6b87df97d24e661a14e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9572b743c6ef4368d2982eff0e135bdd"><td class="memItemLeft" align="right" valign="top">List[float]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">project_image_corner</a> (self, numpy.ndarray robot_pose)</td></tr>
<tr class="memdesc:a9572b743c6ef4368d2982eff0e135bdd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given a robot's pose in the world, determine what the pose of the top left pixel of its image would be in a global image.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">More...</a><br /></td></tr>
<tr class="separator:a9572b743c6ef4368d2982eff0e135bdd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2be5e783e3e48c5db3bc98d9fcab93c1"><td class="memItemLeft" align="right" valign="top">numpy.ndarray&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a2be5e783e3e48c5db3bc98d9fcab93c1">transform_camera_to_world</a> (self, numpy.ndarray robot_pose)</td></tr>
<tr class="memdesc:a2be5e783e3e48c5db3bc98d9fcab93c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given a robot's pose in the world, determine the pose of the camera in the world.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#a2be5e783e3e48c5db3bc98d9fcab93c1">More...</a><br /></td></tr>
<tr class="separator:a2be5e783e3e48c5db3bc98d9fcab93c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a6b6145182312e59eed74154c7607dd9a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6b6145182312e59eed74154c7607dd9a">camera_intrinsic_matrix</a></td></tr>
<tr class="memdesc:a6b6145182312e59eed74154c7607dd9a"><td class="mdescLeft">&#160;</td><td class="mdescRight">The camera intrinsic matrix, generally set in Blender.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6b6145182312e59eed74154c7607dd9a">More...</a><br /></td></tr>
<tr class="separator:a6b6145182312e59eed74154c7607dd9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a424e154611f64ac525e608d53232dc83"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a424e154611f64ac525e608d53232dc83">camera_pose</a></td></tr>
<tr class="memdesc:a424e154611f64ac525e608d53232dc83"><td class="mdescLeft">&#160;</td><td class="mdescRight">The camera's pose, as measured from the robot's frame of reference.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#a424e154611f64ac525e608d53232dc83">More...</a><br /></td></tr>
<tr class="separator:a424e154611f64ac525e608d53232dc83"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-attribs" name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:ad0e3a0959ee569442b2cb87b59920308"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad0e3a0959ee569442b2cb87b59920308">_camera_intrinsic_matrix</a></td></tr>
<tr class="memdesc:ad0e3a0959ee569442b2cb87b59920308"><td class="mdescLeft">&#160;</td><td class="mdescRight">The camera intrinsic matrix, generally set in Blender.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad0e3a0959ee569442b2cb87b59920308">More...</a><br /></td></tr>
<tr class="separator:ad0e3a0959ee569442b2cb87b59920308"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18556d50ee94a7e1c48f481fbb57aaad"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a18556d50ee94a7e1c48f481fbb57aaad">_camera_pose</a></td></tr>
<tr class="memdesc:a18556d50ee94a7e1c48f481fbb57aaad"><td class="mdescLeft">&#160;</td><td class="mdescRight">The camera's pose, as measured from the robot's frame of reference.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#a18556d50ee94a7e1c48f481fbb57aaad">More...</a><br /></td></tr>
<tr class="separator:a18556d50ee94a7e1c48f481fbb57aaad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0ce17c46c2bc9fb8fa4703686d8f0b8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad0ce17c46c2bc9fb8fa4703686d8f0b8">_image_2_camera</a></td></tr>
<tr class="memdesc:ad0ce17c46c2bc9fb8fa4703686d8f0b8"><td class="mdescLeft">&#160;</td><td class="mdescRight">The rotation matrix to transform from image coordinates to camera coordinates.  <a href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad0ce17c46c2bc9fb8fa4703686d8f0b8">More...</a><br /></td></tr>
<tr class="separator:ad0ce17c46c2bc9fb8fa4703686d8f0b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >A class to convert poses and points from one frame to another. </p>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00048">48</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ab2046be7681d2ac072aab5a062ae8c97" name="ab2046be7681d2ac072aab5a062ae8c97"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab2046be7681d2ac072aab5a062ae8c97">&#9670;&nbsp;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None ground_texture_sim.transforms.Transformer.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">numpy.ndarray&#160;</td>
          <td class="paramname"><em>camera_pose</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">numpy.ndarray&#160;</td>
          <td class="paramname"><em>camera_intrinsic_matrix</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Construct the class with the pose of the camera relative to the robot and camera intrinsic matrix. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">camera_pose</td><td>A 4x4 Numpy array that represents the homogenous pose of the camera as measured from the robot's frame of reference. </td></tr>
    <tr><td class="paramname">camera_intrinsic_matrix</td><td>The 3x3 Numpy array that holds the camera's intrinsic matrix. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00053">53</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>
<div class="fragment"><div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>    <span class="keyword">def </span>__init__(self, camera_pose: numpy.ndarray, camera_intrinsic_matrix: numpy.ndarray) -&gt; <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span><span class="stringliteral">        </span><span class="preprocessor">@brief</span> Construct the <span class="keyword">class </span>with the pose of the camera relative to the robot and camera</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>        intrinsic matrix.</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>        <span class="preprocessor">@param</span> camera_pose A 4x4 Numpy array that represents the homogenous pose of the camera <span class="keyword">as</span></div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>        measured <span class="keyword">from</span> the robot<span class="stringliteral">&#39;s frame of reference.</span></div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span><span class="stringliteral">        </span><span class="preprocessor">@param</span> camera_intrinsic_matrix The 3x3 Numpy array that holds the camera<span class="stringliteral">&#39;s intrinsic matrix.</span></div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span><span class="stringliteral">        </span><span class="comment">## The camera&#39;s pose, as measured from the robot&#39;s frame of reference.</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>        self.camera_pose = camera_pose</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>        <span class="comment">## The camera intrinsic matrix, generally set in Blender.</span></div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>        self.camera_intrinsic_matrix = camera_intrinsic_matrix</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>        <span class="comment">## The rotation matrix to transform from image coordinates to camera coordinates.</span></div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>        self._image_2_camera = numpy.array([</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>            [0.0, 0.0, 1.0, 0.0],</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>            [-1.0, 0.0, 0.0, 0.0],</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>            [0.0, -1.0, 0.0, 0.0],</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>            [0.0, 0.0, 0.0, 1.0]</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>        ])</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ab2046be7681d2ac072aab5a062ae8c97">ground_texture_sim.transforms.Transformer.__init__()</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ab2046be7681d2ac072aab5a062ae8c97">ground_texture_sim.transforms.Transformer.__init__()</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="ad6923529981efa026c688314a0895262" name="ad6923529981efa026c688314a0895262"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6923529981efa026c688314a0895262">&#9670;&nbsp;</a></span>camera_intrinsic_matrix() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> numpy.ndarray ground_texture_sim.transforms.Transformer.camera_intrinsic_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Get the 3x3 camera intrinsic matrix. </p>
<dl class="section return"><dt>Returns</dt><dd>A 3x3 Numpy array representing the matrix. </dd></dl>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00074">74</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>
<div class="fragment"><div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>    <span class="keyword">def </span>camera_intrinsic_matrix(self) -&gt; numpy.ndarray:</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span><span class="stringliteral">        </span><span class="preprocessor">@brief</span> Get the 3x3 camera intrinsic matrix.</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>        <span class="preprocessor">@return</span> A 3x3 Numpy array representing the matrix.</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span><span class="stringliteral">        </span><span class="keywordflow">return</span> self._camera_intrinsic_matrix</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad0e3a0959ee569442b2cb87b59920308">ground_texture_sim.transforms.Transformer._camera_intrinsic_matrix</a>, and <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6b6145182312e59eed74154c7607dd9a">ground_texture_sim.transforms.Transformer.camera_intrinsic_matrix</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>.</p>

</div>
</div>
<a id="abd817666244a1508a7859f84533c02e4" name="abd817666244a1508a7859f84533c02e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd817666244a1508a7859f84533c02e4">&#9670;&nbsp;</a></span>camera_intrinsic_matrix() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None ground_texture_sim.transforms.Transformer.camera_intrinsic_matrix </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">numpy.ndarray&#160;</td>
          <td class="paramname"><em>camera_intrinsic_matrix</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set the camera intrinsic matrix. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">camera_intrinsic_matrix</td><td>A 3x3 Numpy array representing the matrix. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">ValueError</td><td>if the provided matrix is not 3x3. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00082">82</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>
<div class="fragment"><div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>    <span class="keyword">def </span>camera_intrinsic_matrix(self, camera_intrinsic_matrix: numpy.ndarray) -&gt; <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span><span class="stringliteral">        </span><span class="preprocessor">@brief</span> Set the camera intrinsic matrix.</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>        <span class="preprocessor">@param</span> camera_intrinsic_matrix A 3x3 Numpy array representing the matrix.</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>        <span class="preprocessor">@return</span> <span class="keywordtype">None</span></div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>        <span class="preprocessor">@exception</span> ValueError <span class="keywordflow">if</span> the provided matrix <span class="keywordflow">is</span> <span class="keywordflow">not</span> 3x3.</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span><span class="stringliteral">        </span><span class="keywordflow">if</span> camera_intrinsic_matrix.shape != (3, 3):</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>                F<span class="stringliteral">&#39;Provided intrinsic matrix should be shape (3, 3), &#39;</span></div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>                F<span class="stringliteral">&#39;not {camera_intrinsic_matrix.shape}.&#39;</span>)</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>        <span class="comment">## The camera intrinsic matrix, generally set in Blender.</span></div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>        self._camera_intrinsic_matrix = camera_intrinsic_matrix</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6b6145182312e59eed74154c7607dd9a">ground_texture_sim.transforms.Transformer.camera_intrinsic_matrix</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>.</p>

</div>
</div>
<a id="a6fac7a1c805cf77c99e98b38139fdd6d" name="a6fac7a1c805cf77c99e98b38139fdd6d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6fac7a1c805cf77c99e98b38139fdd6d">&#9670;&nbsp;</a></span>camera_pose() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> numpy.ndarray ground_texture_sim.transforms.Transformer.camera_pose </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Get the 4x4 homogenous pose of the camera as measured from the robot. </p>
<dl class="section return"><dt>Returns</dt><dd>A 4x4 Numpy array representing the pose. </dd></dl>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00097">97</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>
<div class="fragment"><div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>    <span class="keyword">def </span>camera_pose(self) -&gt; numpy.ndarray:</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span><span class="stringliteral">        </span><span class="preprocessor">@brief</span> Get the 4x4 homogenous pose of the camera <span class="keyword">as</span> measured <span class="keyword">from</span> the robot.</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>        <span class="preprocessor">@return</span> A 4x4 Numpy array representing the pose.</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span><span class="stringliteral">        </span><span class="keywordflow">return</span> self._camera_pose</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classground__texture__sim_1_1script__runner_1_1GroundTextureSim.html#a555a2b7afd029a46d59d6a2ca98723d7">ground_texture_sim.script_runner.GroundTextureSim._camera_pose</a>, <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a18556d50ee94a7e1c48f481fbb57aaad">ground_texture_sim.transforms.Transformer._camera_pose</a>, and <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a424e154611f64ac525e608d53232dc83">ground_texture_sim.transforms.Transformer.camera_pose</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>, and <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a2be5e783e3e48c5db3bc98d9fcab93c1">ground_texture_sim.transforms.Transformer.transform_camera_to_world()</a>.</p>

</div>
</div>
<a id="ac84a739200ea6b87df97d24e661a14e6" name="ac84a739200ea6b87df97d24e661a14e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac84a739200ea6b87df97d24e661a14e6">&#9670;&nbsp;</a></span>camera_pose() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None ground_texture_sim.transforms.Transformer.camera_pose </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">numpy.ndarray&#160;</td>
          <td class="paramname"><em>camera_pose</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set the pose of the camera as measured from the robot's frame of reference. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">camera_pose</td><td>A 4x4 Numpy array containing a homogenous pose. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">ValueError</td><td>if the provided matrix is not 4x4. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00105">105</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>
<div class="fragment"><div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>    <span class="keyword">def </span>camera_pose(self, camera_pose: numpy.ndarray) -&gt; <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span><span class="stringliteral">        </span><span class="preprocessor">@brief</span> Set the pose of the camera <span class="keyword">as</span> measured <span class="keyword">from</span> the robot<span class="stringliteral">&#39;s frame of reference.</span></div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span><span class="stringliteral">        </span><span class="preprocessor">@param</span> camera_pose A 4x4 Numpy array containing a homogenous pose.</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>        <span class="preprocessor">@return</span> <span class="keywordtype">None</span></div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>        <span class="preprocessor">@exception</span> ValueError <span class="keywordflow">if</span> the provided matrix <span class="keywordflow">is</span> <span class="keywordflow">not</span> 4x4.</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span><span class="stringliteral">        </span><span class="keywordflow">if</span> camera_pose.shape != (4, 4):</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>            <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>                F<span class="stringliteral">&#39;Provided intrinsic matrix should be shape (4, 4), not {camera_pose.shape}.&#39;</span>)</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>        <span class="comment">## The camera&#39;s pose, as measured from the robot&#39;s frame of reference.</span></div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>        self._camera_pose = camera_pose</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a424e154611f64ac525e608d53232dc83">ground_texture_sim.transforms.Transformer.camera_pose</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>, and <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a2be5e783e3e48c5db3bc98d9fcab93c1">ground_texture_sim.transforms.Transformer.transform_camera_to_world()</a>.</p>

</div>
</div>
<a id="a9572b743c6ef4368d2982eff0e135bdd" name="a9572b743c6ef4368d2982eff0e135bdd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9572b743c6ef4368d2982eff0e135bdd">&#9670;&nbsp;</a></span>project_image_corner()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> List[float] ground_texture_sim.transforms.Transformer.project_image_corner </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">numpy.ndarray&#160;</td>
          <td class="paramname"><em>robot_pose</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Given a robot's pose in the world, determine what the pose of the top left pixel of its image would be in a global image. </p>
<p >This global image is aligned with the image obtained when the robot is at the origin of the world. The pixel value of the corner is found by first projecting it into the robot's frame of reference. Then, it is transformed to the origin's frame of reference and projected back into this global aligned image.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">robot_pose</td><td>A 4x4 Numpy array containing the homogenous representation of the robot as measured from the world frame. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A 3 element list containing the X (in pixels), Y (in pixels), and yaw (in radians) of the top left corner of the image. </dd></dl>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00118">118</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>
<div class="fragment"><div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>    <span class="keyword">def </span>project_image_corner(self, robot_pose: numpy.ndarray) -&gt; List[float]:</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span><span class="stringliteral">        </span><span class="preprocessor">@brief</span> Given a robot<span class="stringliteral">&#39;s pose in the world, determine what the pose of the top left pixel of</span></div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span><span class="stringliteral">        its image would be </span><span class="keywordflow">in</span> a <span class="keyword">global</span> image.</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span> </div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>        This <span class="keyword">global</span> image <span class="keywordflow">is</span> aligned <span class="keyword">with</span> the image obtained when the robot <span class="keywordflow">is</span> at the origin of the</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>        world. The pixel value of the corner <span class="keywordflow">is</span> found by first projecting it into the robot<span class="stringliteral">&#39;s frame</span></div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span><span class="stringliteral">        of reference. Then, it </span><span class="keywordflow">is</span> transformed to the origin<span class="stringliteral">&#39;s frame of reference and projected</span></div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span><span class="stringliteral">        back into this </span><span class="keyword">global</span> aligned image.</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span> </div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>        <span class="preprocessor">@param</span> robot_pose A 4x4 Numpy array containing the homogenous representation of the robot <span class="keyword">as</span></div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>        measured <span class="keyword">from</span> the world frame.</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>        <span class="preprocessor">@return</span> A 3 element list containing the X (<span class="keywordflow">in</span> pixels), Y (<span class="keywordflow">in</span> pixels), <span class="keywordflow">and</span> yaw (<span class="keywordflow">in</span> radians)</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>        of the top left corner of the image.</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span><span class="stringliteral">        </span><span class="comment"># The top left corner is always (0, 0) in pixel space. Add the one for the transform math to</span></div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>        <span class="comment"># work. This will then become the Z component after the scale is applied.</span></div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>        point_robot_pixel = numpy.array([0.0, 0.0, 1.0]).transpose()</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>        <span class="comment"># Project from pixel space to image coordinates, which are centered in the image with +X to</span></div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>        <span class="comment"># the right of the image and +Y down the image. This normally is only correct to a scale</span></div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>        <span class="comment"># factor of the depth, but we know the depth in this case.</span></div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>        point_robot_image_truncated = (numpy.linalg.inv(self.camera_intrinsic_matrix) @</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>                                       point_robot_pixel) * self.camera_pose[2, 3]</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>        <span class="comment"># Now transform to the robot&#39;s origin. This requires adding a 1 to be a homogenous</span></div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>        <span class="comment"># representation.</span></div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>        point_robot_image = numpy.append(point_robot_image_truncated, [1.0], 0)</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>        point_robot = self.camera_pose @ self._image_2_camera @ point_robot_image</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>        <span class="comment"># Now transform to the origin frame based on the robot&#39;s pose</span></div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>        point_origin = robot_pose @ point_robot</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>        <span class="comment"># Then, transform back into the image frame as if there was a robot aligned at this point.</span></div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>        point_origin_image = numpy.linalg.inv(</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>            self.camera_pose @ self._image_2_camera) @ point_origin</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>        <span class="comment"># Normalize to the camera height, then drop the Z component as it is not needed for point</span></div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>        <span class="comment"># projection</span></div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>        point_origin_image /= self.camera_pose[2, 3]</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>        point_origin_image_truncated = numpy.array(</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>            [point_origin_image[0], point_origin_image[1], 1.0]).transpose()</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>        <span class="comment"># Finally, project into the pixel space.</span></div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>        point_origin_pixel = (self.camera_intrinsic_matrix @</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>                              point_origin_image_truncated).squeeze()</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>        <span class="comment"># Get the yaw from the robot&#39;s original yaw.</span></div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>        yaw = numpy.arccos(robot_pose[0, 0])</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>        <span class="keywordflow">if</span> numpy.sign(robot_pose[1, 0]) == -1:</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>            yaw *= -1.0</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>        <span class="keywordflow">return</span> [point_origin_pixel[0], point_origin_pixel[1], yaw]</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad0ce17c46c2bc9fb8fa4703686d8f0b8">ground_texture_sim.transforms.Transformer._image_2_camera</a>, <a class="el" href="classground__texture__sim_1_1blender__interface_1_1BlenderInterface.html#a7fa4a6a2e4ba56bb98368b2dba0f990e">ground_texture_sim.blender_interface.BlenderInterface.camera_intrinsic_matrix()</a>, <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6b6145182312e59eed74154c7607dd9a">ground_texture_sim.transforms.Transformer.camera_intrinsic_matrix</a>, <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a424e154611f64ac525e608d53232dc83">ground_texture_sim.transforms.Transformer.camera_pose</a>, and <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>.</p>

</div>
</div>
<a id="a2be5e783e3e48c5db3bc98d9fcab93c1" name="a2be5e783e3e48c5db3bc98d9fcab93c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2be5e783e3e48c5db3bc98d9fcab93c1">&#9670;&nbsp;</a></span>transform_camera_to_world()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> numpy.ndarray ground_texture_sim.transforms.Transformer.transform_camera_to_world </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">numpy.ndarray&#160;</td>
          <td class="paramname"><em>robot_pose</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Given a robot's pose in the world, determine the pose of the camera in the world. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">robot_pose</td><td>A 4x4 Numpy array containing the homogenous representation of the robot as measured from the world frame. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A 4x4 Numpy array representing the pose of the camera as measured from the world frame. </dd></dl>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00164">164</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>
<div class="fragment"><div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>    <span class="keyword">def </span>transform_camera_to_world(self, robot_pose: numpy.ndarray) -&gt; numpy.ndarray:</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>        <span class="stringliteral">&quot;&quot;&quot;!</span></div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span><span class="stringliteral">        </span><span class="preprocessor">@brief</span> Given a robot<span class="stringliteral">&#39;s pose in the world, determine the pose of the camera in the world.</span></div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span><span class="stringliteral">        </span><span class="preprocessor">@param</span> robot_pose A 4x4 Numpy array containing the homogenous representation of the robot <span class="keyword">as</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>        measured <span class="keyword">from</span> the world frame.</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>        <span class="preprocessor">@return</span> A 4x4 Numpy array representing the pose of the camera <span class="keyword">as</span> measured <span class="keyword">from</span> the world</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>        frame.</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span><span class="stringliteral">        </span><span class="keywordflow">return</span> robot_pose @ self.camera_pose</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a424e154611f64ac525e608d53232dc83">ground_texture_sim.transforms.Transformer.camera_pose</a>, and <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a2be5e783e3e48c5db3bc98d9fcab93c1">ground_texture_sim.transforms.Transformer.transform_camera_to_world()</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a2be5e783e3e48c5db3bc98d9fcab93c1">ground_texture_sim.transforms.Transformer.transform_camera_to_world()</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="ad0e3a0959ee569442b2cb87b59920308" name="ad0e3a0959ee569442b2cb87b59920308"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0e3a0959ee569442b2cb87b59920308">&#9670;&nbsp;</a></span>_camera_intrinsic_matrix</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">ground_texture_sim.transforms.Transformer._camera_intrinsic_matrix</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The camera intrinsic matrix, generally set in Blender. </p>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00094">94</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad6923529981efa026c688314a0895262">ground_texture_sim.transforms.Transformer.camera_intrinsic_matrix()</a>.</p>

</div>
</div>
<a id="a18556d50ee94a7e1c48f481fbb57aaad" name="a18556d50ee94a7e1c48f481fbb57aaad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18556d50ee94a7e1c48f481fbb57aaad">&#9670;&nbsp;</a></span>_camera_pose</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">ground_texture_sim.transforms.Transformer._camera_pose</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The camera's pose, as measured from the robot's frame of reference. </p>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00116">116</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6fac7a1c805cf77c99e98b38139fdd6d">ground_texture_sim.transforms.Transformer.camera_pose()</a>, and <a class="el" href="classground__texture__sim_1_1script__runner_1_1GroundTextureSim.html#aff9a3d3c2c43be1b9fff8d731f74feb7">ground_texture_sim.script_runner.GroundTextureSim.run()</a>.</p>

</div>
</div>
<a id="ad0ce17c46c2bc9fb8fa4703686d8f0b8" name="ad0ce17c46c2bc9fb8fa4703686d8f0b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0ce17c46c2bc9fb8fa4703686d8f0b8">&#9670;&nbsp;</a></span>_image_2_camera</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">ground_texture_sim.transforms.Transformer._image_2_camera</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The rotation matrix to transform from image coordinates to camera coordinates. </p>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00066">66</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>.</p>

</div>
</div>
<a id="a6b6145182312e59eed74154c7607dd9a" name="a6b6145182312e59eed74154c7607dd9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b6145182312e59eed74154c7607dd9a">&#9670;&nbsp;</a></span>camera_intrinsic_matrix</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">ground_texture_sim.transforms.Transformer.camera_intrinsic_matrix</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The camera intrinsic matrix, generally set in Blender. </p>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00064">64</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#ad6923529981efa026c688314a0895262">ground_texture_sim.transforms.Transformer.camera_intrinsic_matrix()</a>, and <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>.</p>

</div>
</div>
<a id="a424e154611f64ac525e608d53232dc83" name="a424e154611f64ac525e608d53232dc83"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a424e154611f64ac525e608d53232dc83">&#9670;&nbsp;</a></span>camera_pose</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">ground_texture_sim.transforms.Transformer.camera_pose</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The camera's pose, as measured from the robot's frame of reference. </p>

<p class="definition">Definition at line <a class="el" href="transforms_8py_source.html#l00062">62</a> of file <a class="el" href="transforms_8py_source.html">transforms.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a6fac7a1c805cf77c99e98b38139fdd6d">ground_texture_sim.transforms.Transformer.camera_pose()</a>, <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a9572b743c6ef4368d2982eff0e135bdd">ground_texture_sim.transforms.Transformer.project_image_corner()</a>, and <a class="el" href="classground__texture__sim_1_1transforms_1_1Transformer.html#a2be5e783e3e48c5db3bc98d9fcab93c1">ground_texture_sim.transforms.Transformer.transform_camera_to_world()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>ground_texture_sim/<a class="el" href="transforms_8py_source.html">transforms.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.2
</small></address>
</body>
</html>
